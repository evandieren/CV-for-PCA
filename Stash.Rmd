---
title: "Stash"
author: "Noah Scheider"
date: "2022-12-23"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Fixing our data set to be $D_0$ and applying our CV Methods, we get very different results for each algorithm. Please note that the $y$-axis in in logscale in order to get meaningful insights about the errors, especially for the [Missing Data approach]. First, the error of the [Naïve Approach] decreases continuously and achieves its best estimation when allowing the method to make use of all $8$ variables, as theoretically expected.

The Wrong PCA Method Improved method will however counter this behavior and the error will rise after hitting the optimal $r=3$ value. Overall this would lead the Wrong PCA Improved Method to favor rank $3$ as estimate for the rank of our modified data set. In general we can still see that the Wrong PCA Improved has difficulties to extract the exact amount of variables, especially when the added noise to the data set is constantly high, as the high curve in yellow is less steep than the blue one with low noise. We also note that for the high noise curve, there is a tendency to revert back when $r$ increases, which might cause problems as the biggest value $r$ might be returned.

The [Missing data approach] differs in its overall behavior from the previous to methods. While the error only decreases slightly in the first and the second variable, it drops noticeably for $r=3$ in our Simulation Study especially for low and differing noise. Exceeding rank $3$, there is a strong increase in the error due to the $\Sigma$ estimation of the EM-Algorithm diverging from the expected value. A possible reason for this divergence is the choice of initial covariance matrix (in our case the Identity matrix). Here, we conclude the this approach also finds the correct dimension, but one has to be careful of the amount of noise added as this challenges the algorithm quite a bit.

The error measure of the [Matrix completion method] seems to be a mix of the error of the Wrong PCA Improved and the Missing Data approach. We observe a slight increase in the first two variables, followed by a strong error drop on variable $3$ before it starts to increase again. The increase after variable $3$ is clearly stronger than at the beginning.

As for the [KDE Modified Approach], it will be analysed at the end of this section due to similar behaviors with respect to different datasets.

After this initial analysis, one would like to examine how the CV methods generalize to other datasets, i.e. moving from the identity matrix as covariance to a random matrix. Hereafter are the results for $D_1$, being the dataset with a random covariance matrix, as defined in the [Simulation dataset description]

```{r Noise1, echo=FALSE,out.width="80%", fig.align = 'center', fig.width=12,fig.height=8,fig.cap = "Comparison of CV methods on base 1 dataset with different noises as indicated by Noise°1,2 and 3"}
par(mfrow=c(2,2))
plot_dataset_together("Wrong PCA",1,T)
plot_dataset_together("Wrong PCA Improved",1,T)
plot_dataset_together("Missing Data",1,T)
plot_dataset_together("Matrix Completion",1,T)
```

<<<<<<< HEAD
The [Naive Approach] seems to preserve the same shape and error size as on $D_0$. The Wrong PCA Improved method slightly changes as it still drops in within the first three variables, but stabilizes more strongly afterwards. Again we see how the total noise added accounts for the different stabilization errors. For the Missing Data Approach error we observe a strong similarity to the previous analysis. Its error starts to decrease until variable $3$ and then spikes up to stabilize. The only noticable difference is, that the total amount of noise added plays now a stronger criterion on where the curve converges. With the uniform low noise converging with the lowest error. In the Matrix Completion method we now observe that the algorithms doesn't screw up its prediction with high uniform noise, but does this time for differing noise. For high noise the method favors $3$ variables, where as it chooses $2$ variables for differing noise. For a uniform low noise it seems to work well by, having a sharp decrease in error rank $3$ and then increasing again.

We now examine to which extent our algorithms change if we consider a structured covariance $\Sigma_2$, with increasing impact on the last variables.
=======
The [Naïve Approach] seems to preserve the same shape and error size as on $D_0$. The Wrong PCA Improved method slightly changes as it still drops in within the first three variables, but stabilizes more strongly afterwards especially for Noise n°3. Again we see how the total noise added accounts for the different stabilization error. Interestingly, the Missing Data Approach  and the Matrix Completion Method aren't able to return more precise estimation with a higher amount of variables and actually increase in error size. Both have kind of the same shape and error size, whereas the latter one seems to be a smoother version of the first one. Also the error curve sticks closely together for the uniform noise in the Missing Data Approach, whereas the differing noise starts beneath the  and starts beneath 
>>>>>>> 42feed500abe249bc11b9e390e35b03af0f321e8

```{r Noise2, echo=FALSE,out.width="80%", fig.align = 'center', fig.width=12,fig.height=8,fig.cap = "Comparison of CV methods on base 2 dataset with different noises as indicated by Noise°1,2 and 3"}
par(mfrow=c(2,2))
plot_dataset_together("Wrong PCA",2,T)
plot_dataset_together("Wrong PCA Improved",2,T)
plot_dataset_together("Missing Data",2,T)
plot_dataset_together("Matrix Completion",2,T)
```

<<<<<<< HEAD
The Wrong PCA has behaves again the same regardless of the noise added. The first observation also applies for the Wrong PCA improved. The only subtlety we want to emphasize on, is that it seems once again to be sensitive with the total amount of noise added. A stronger decrease in the first two variables for the uniform and differing noise is observable.
Interestingly, the Missing Data Approach  and the Matrix Completion Method don't seem to handle the kind of structure very well. In fact the algorithms aren't able to return more precise estimation with a higher amount of variables and actually increase in error size. Both have kind of the same shape and error size, whereas the latter one seems to be a smoother version of the first one. Also the error curve sticks closely together for the uniform noise in the Missing Data Approach, whereas the differing noise starts beneath the other two error curves but then exceed them after rank $5$. The adhesivity is somewhat stronger for the error  Matrix completion error as the error curve is almost identical regardless of the noise added.

```{r NoiseMissing0, echo=FALSE,out.width="80%", fig.align = 'center', fig.width=12,fig.height=4,fig.cap = "KDE Approach for base 0 dataset with different noises as indicated by Noise°1,2 and 3"}
plot_three("KDE Approach",0)
=======
```{r NoiseKDE, echo=FALSE,out.width="80%", fig.align = 'center', fig.width=12,fig.height=4,fig.cap = "KDE Modified Approach for the 3 datasets with different noises as indicated by Noise°1,2 and 3"}
par(mfrow=c(1,3))
plot_dataset_together("KDE Approach",0,F)
plot_dataset_together("KDE Approach",1,F)
plot_dataset_together("KDE Approach",2,F)
>>>>>>> 42feed500abe249bc11b9e390e35b03af0f321e8
```


For the [KDE Modified Approach], we observe in general that for every variable until the third one it drops very strongly. Having reached rank $3$ the quality of its estimation seem to stay the same and correspondingly the error. In case of the second data set we observe the same behaviour but instead of stabilizing after rank $3$ it does that after reaching variable $2$ by construction of our data set.
